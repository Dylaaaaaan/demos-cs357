{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tumor is a mass of abnormal tissue. Malignant and benign tumors have different cell growth characteristics.\n",
    "\n",
    "For this activity, you will use python libraries such as `seaborn` and `scikit-learn` to:\n",
    "\n",
    "* explore the data using vizualization tools\n",
    "* run PCA to reduce the dimension of the dataset\n",
    "* split your data into training and test sets\n",
    "* create a model to predict wheter a tumor is malignant (cancerous / deadly) or benign (non-cancerous / safe) based on the tumor properties. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [\"radius\", \"texture\", \"perimeter\", \"area\",\n",
    "          \"smoothness\", \"compactness\", \"concavity\",\n",
    "          \"concave points\", \"symmetry\", \"fractal dimension\"];\n",
    "stats = [\"(mean)\", \"(stderr)\", \"(worst)\"]\n",
    "labels = [\"patient ID\", \"Malignant/Benign\"]\n",
    "\n",
    "for p in params:\n",
    "    for s in stats:\n",
    "        labels.append(p + \" \" + s)\n",
    "\n",
    "tumor_data = pd.io.parsers.read_csv(\"breast-cancer-dataset.dat\",header=None,names=labels)\n",
    "\n",
    "feature_labels = labels[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many features in this dataset? How many patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of patients =  560\n",
      "# of features =  30\n"
     ]
    }
   ],
   "source": [
    "#clear\n",
    "M = len(tumor_data)\n",
    "N = len(feature_labels)\n",
    "print(\"# of patients = \", M)\n",
    "print(\"# of features = \", N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the first few lines of your data using `tumor_data.head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "tumor_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `X` as the dataset with the features for all patients (not including the patient ID and diagnosis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "X = tumor_data[feature_labels]\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the mean value for each feature using `X.mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "X.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the standard deviation for each feature using X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Y, an array with the diagnosis for each patient. We will later use a classification algorithm to help predict patient's diagnosis (based on the features, should a patient tumor be classified as a `M` or `B`?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "Y = tumor_data['Malignant/Benign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purposes only, you can select a subset of the features, and use \n",
    "\n",
    "`seaborn.pairplot(data)`\n",
    "\n",
    "to plot pairwise relationships in the dataset (you could plot all of the feature pairs, but this would generate a lot of plots!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_label = [labels[1]] + labels[2::3] \n",
    "#sns.pairplot(tumor_data[mean_label], hue=\"Malignant/Benign\", plot_kws = {'alpha': 0.6, 's': 80, 'edgecolor': 'k'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can look at the plot of the correlation matrix for all the featues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = X.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure(figsize = (14,8))\n",
    "ax1 = fig.add_subplot(111)\n",
    "cax = ax1.imshow(corr_matrix, cmap=cm.get_cmap('jet'))\n",
    "plt.title('Tumor features correlation matrix')\n",
    "plt.grid(False)\n",
    "ax1.set_xticks(np.arange(len(feature_labels)))\n",
    "ax1.set_yticks(np.arange(len(feature_labels)))\n",
    "ax1.set_xticklabels(feature_labels,fontsize=10,rotation=90)\n",
    "ax1.set_yticklabels(feature_labels,fontsize=10)\n",
    "fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwhelming? Don’t worry, in some cases the effective dimension of your problem might be much smaller than the number of the features, such as in data sets where some features are irrelevant. Is that the case here? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the model’s performance later, we divide the dataset into two parts: a training set and a test set. The first is used to train the system, while the second is used to evaluate the learned or trained system. \n",
    "\n",
    "We are going to use `sklearn.model_selection.train_test_split` to split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common splitting choice is to take 2/3 of your original data set as the training set, while the 1/3 that remains will compose the test set. You should select this proportion by assigning the variable `s` and setting the argument `test_sizes = s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear \n",
    "s = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fix the seed for the random number generator, in order to get reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use:  `X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=s, random_state=seed)`\n",
    "\n",
    "to split the dataset into the set of features and diagnosis used for training (X_train,Y_train) and a set used for evaluating the trained system (X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=s, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "When you use algorithms for classification tasks, not all features will contribute well to the generalization capacity of your model. Some irrelevant and correlated attributes can even decrease the performance of some algorithms, contributing to overfitting, for example.\n",
    "\n",
    "It is now your responsibility to choose the best set of features that will make your models performs better! Use  PCA to reduce the feature space of the training set while still retaining the most meaningful information about the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Scaling the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now `center the training data` by making it have zero mean and unit standard deviation. We will first do this step explicility, like we have done in previous activities, before calling SVD to compute the variances. Let's revise how we were solving PCA before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xzero = X_train-X_train.mean()\n",
    "Xscaled = Xzero/X_train.std()\n",
    "U,sigma,Vt = la.svd(Xzero,full_matrices=False)\n",
    "variance=sigma**2\n",
    "total_variance = sum(variance)\n",
    "print(variance/total_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, we will use the PCA class from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA class scales the data to have zero mean. We can also use the method\n",
    "\n",
    "`pca.explained_variance_ratio_`\n",
    "\n",
    "to obtain the explained variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.80235252e-01   1.76388461e-02   1.90610748e-03   1.20447599e-04\n",
      "   8.72383033e-05   6.84948034e-06   3.78245320e-06   8.65500617e-07\n",
      "   3.55017700e-07   1.58090830e-07   6.51888543e-08   1.49593710e-08\n",
      "   6.92494738e-09   4.50523385e-09   3.03706337e-09   1.27544572e-09\n",
      "   8.53783527e-10   4.87077530e-10   4.12137475e-10   3.36099268e-10\n",
      "   1.68075533e-10   1.30882995e-10   8.10116499e-11   5.40419239e-11\n",
      "   3.54896936e-11   2.75410670e-11   7.61430739e-12   6.24731176e-12\n",
      "   4.98193116e-12   1.63035465e-12]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA().fit(X_train)\n",
    "print(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we obtained the same explained variances when using SVD in 'Xzero'. \n",
    "\n",
    "In this tutorial, we will use the library `StandardScaler` to scale the training set for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`scaler = StandardScaler().fit(X_train)`\n",
    "\n",
    "\n",
    "sklearn's transform's fit() just calculates the parameters (e.g. 𝜇 and 𝜎 in case of StandardScaler) and saves them as an internal objects state. Afterwards, you can call its transform() method to apply the transformation to a particular set of examples.\n",
    "\n",
    "`Xs_train = scaler.transform(X_train)`\n",
    "\n",
    "We will later apply the same transformation to the testing set, using the same two parameters 𝜇 and 𝜎 (values) that you used for centering the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xs_train = scaler.transform(X_train) \n",
    "Xs_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Fitting the PCA algorithm with the rescaled training set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, all we have to do now is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.30255335e-01   1.96996395e-01   1.00129588e-01   6.58115680e-02\n",
      "   5.43017590e-02   4.00702846e-02   2.22959251e-02   1.66088475e-02\n",
      "   1.30348731e-02   1.15705377e-02   1.00644698e-02   9.06789620e-03\n",
      "   8.28608754e-03   5.36584258e-03   2.99146910e-03   2.45522098e-03\n",
      "   2.12900097e-03   1.72582342e-03   1.56893905e-03   1.04893989e-03\n",
      "   9.49736547e-04   8.85518251e-04   7.65335345e-04   5.56751131e-04\n",
      "   4.83118271e-04   2.65795914e-04   2.30387337e-04   5.37173237e-05\n",
      "   2.67907073e-05   4.04699316e-06]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA().fit(Xs_train)\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "print(var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check above that you would obtain the same explained variances if you have used `Xscaled` to obtain the SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Deciding the number of principal components to use for the classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the explained variance and the cummulative explained variance. If you want to retain the principal components that capture 80% of the variance, how many components should you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(cum_var_exp)\n",
    "\n",
    "plt.bar(range(len(var_exp)), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "plt.step(range(len(var_exp)), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Creating the new (reduced) dataset for the classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the variable `Z_train` the projected training set with reduced feature space that captures 90% of the variance (remember `Z_train = X_train V` where `V` is the right singular vector matrix?) \n",
    "\n",
    "How many components should you consider?\n",
    "\n",
    "Two different approaches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "#clear\n",
    "# if 0 < n_components < 1, it will be treated as the amount of variance being preserved\n",
    "pca = PCA(.9).fit(Xs_train)\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clear\n",
    "# equivalent as above\n",
    "pca = PCA(n_components=7).fit(Xs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now project your test set onto the Principal Components of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z_train = pca.transform(Xs_train)\n",
    "Z_test = pca.transform(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set colors for each data point\n",
    "C = []\n",
    "classes = list(set(Y_train))\n",
    "for c in Y_train:\n",
    "    if c == classes[0]:\n",
    "        C.append('r')\n",
    "    else:\n",
    "        C.append('b')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Training Data Projected into 2D Subspace\")\n",
    "plt.xlabel(\"1st Component\")\n",
    "plt.ylabel(\"2nd Component\")\n",
    "\n",
    "plt.scatter(Z_train[:, 0], Z_train[:, 1], c=C)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first use a logistic regression model. This is used for classification tasks where data points can only be a member of one class. The model can be solved either using a modified version of least squares or newton's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an instance of the model, using all the default parameters for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 7) (392, 30)\n"
     ]
    }
   ],
   "source": [
    "#Recall...\n",
    "print(Z_train.shape,Xs_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Z_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the trained model, you can get the predicted diagnosis for the patients in the set `X_test`, and compare them with the `actual` diagnosis in `Y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ypredict = model.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98809523809523814"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy: Overall, how often is the classifier correct?\n",
    "(Y_test==Ypredict).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.988095238095\n"
     ]
    }
   ],
   "source": [
    "test_score = model.score(Z_test, Y_test)\n",
    "print(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: describes the performance of the classification model on a set of test data for which the true values are known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56   1]\n",
      " [  1 110]]\n"
     ]
    }
   ],
   "source": [
    "# use \"labels\" argument to re-organize the entries in the confusion matrix\n",
    "# (we typically treat malignant as positive and benign as negative)\n",
    "cmat = confusion_matrix(Y_test,Ypredict, labels=[\"M\", \"B\"])\n",
    "print(cmat)\n",
    "TP, FP, FN, TN = cmat.ravel()\n",
    "npatients = Y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix = $ \\begin{bmatrix} \n",
    "\\textrm{Predicted positive and actual positive} & \\textrm{Predicted positive and actual negative} \\\\\n",
    "\\textrm{Predicted negative and actual positive} & \\textrm{Predicted negative and actual negative}\\end{bmatrix} = \\begin{bmatrix} \n",
    "\\textrm{TP} & \\textrm{FP} \\\\\n",
    "\\textrm{FN} & \\textrm{TN} \n",
    "\\end{bmatrix}$\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP: Predicted yes (malignant cancer), and the patients do have the disease. (How many malignant tumors are correctly identified? )\n",
    "\n",
    "FP: Predicted yes (malignant cancer), but patients don't actually have the disease. (How many benign tumors are identified as malignant? Also known as a \"Type I error.\")\n",
    "\n",
    "FN: Predicted no (benign cancer), but the patients actually have the disease. (How many malignant tumors are missed? Also known as a \"Type II error.\")\n",
    "\n",
    "TN: Predicted no (benign cancer), and patients don't have the disease. (How mamy benign tumors are correctly identified?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98809523809523814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy: Overall, how often is the classifier correct? We sum the diagonal of the confusion matrix!\n",
    "(TP+TN)/npatients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not always a reliable metric for the real performance of a classifier. Let's say there are 100 patients and 5 have malignant cancer. If the model classifies all the 100 patients as not having cancer, than the overall accuracy is 95% (TP = 0, TN = 95, FN = 5, FP = 0). \n",
    "\n",
    "Let's take a look at other metrics:\n",
    "\n",
    "True positive rate (TPR), or sensitivity or recall: When it's actually yes, how often does it predict yes?\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "True negative rate (TNR) or specificity:  When it's actually no, how often does it predict no?\n",
    "TNR = TN/(FP+TN)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example above, the classifier has 100% specificity (predicts 100% of the benign cancers) and 0% sensitivity (fails to classify all cancerous tumors).\n",
    "\n",
    "The \"best\" metric to use will depend on the classification problem. Back to our original dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982456140351\n"
     ]
    }
   ],
   "source": [
    "# True positive rate (TPR), or sensitivity or recall: When it's actually yes, how often does it predict yes?\n",
    "TPR = TP/(TP+FN)\n",
    "print(TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990990990991\n"
     ]
    }
   ],
   "source": [
    "# True negative rate(TNR) or specificity:  When it's actually no, how often does it predict no?\n",
    "TNR = TN/(FP+TN)   \n",
    "print(TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982456140351\n"
     ]
    }
   ],
   "source": [
    "# Precision: When it predicts yes, how often is it correct?\n",
    "p = TP/(TP+FP)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking other algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Linear SVM\": SVC(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine accuracy of classifier given data pairs (X, Y)\n",
    "def accuracy(classifier, X, Y):\n",
    "    Ypredict = classifier.predict(X)\n",
    "    return (Y==Ypredict).mean()\n",
    "\n",
    "def batch_classify(X_train, Y_train, X_test, Y_test, verbose = True):\n",
    "    print(\"{:34s}{:15s}{:12s}{:12s}\".format(\"Classifiers\", \"Test-score\", \"TPR\", \"TNR\"))\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    labels = []\n",
    "\n",
    "    for classifier_name, classifier in list(dict_classifiers.items()):\n",
    "        \n",
    "        # Fit the model\n",
    "        labels.append(classifier_name)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        # Make predictions on the test data\n",
    "        predictions = classifier.predict(X_test)\n",
    "        cmat = confusion_matrix(Y_test, predictions, labels=[\"M\", \"B\"])\n",
    "        TP, FP, FN, TN = cmat.ravel()\n",
    "        # Get scores\n",
    "        train_score.append(accuracy(classifier, X_train, Y_train))\n",
    "        test_score.append(accuracy(classifier, X_test, Y_test))\n",
    "        if verbose:\n",
    "            print(\"{c:30}{t1:12f}{t2:12f}{t3:12f}\".format(c=classifier_name,t1=test_score[-1], t2=TP/(TP+FN), t3=TN/(FP+TN) ), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers                       Test-score     TPR         TNR         \n",
      "Logistic Regression               0.988095    0.982456    0.990991\n",
      "Nearest Neighbors                 0.964286    0.947368    0.972973\n",
      "Linear SVM                        0.970238    0.948276    0.981818\n",
      "Gradient Boosting Classifier      0.970238    0.948276    0.981818\n",
      "Random Forest                     0.940476    0.943396    0.939130\n",
      "Naive Bayes                       0.922619    0.940000    0.915254\n"
     ]
    }
   ],
   "source": [
    "batch_classify(Z_train, Y_train, Z_test, Y_test, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers                       Test-score     TPR         TNR         \n",
      "Logistic Regression               0.988095    0.982456    0.990991\n",
      "Nearest Neighbors                 0.976190    0.981818    0.973451\n",
      "Linear SVM                        0.964286    0.947368    0.972973\n",
      "Gradient Boosting Classifier      0.958333    0.946429    0.964286\n",
      "Random Forest                     0.970238    1.000000    0.956897\n",
      "Naive Bayes                       0.934524    0.925926    0.938596\n"
     ]
    }
   ],
   "source": [
    "batch_classify(Xs_train, Y_train, Xs_test, Y_test, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
