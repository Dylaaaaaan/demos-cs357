{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matrix norms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# https://matplotlib.org/users/customizing.html\n",
        "# print(plt.style.available) # uncomment to print all styles\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=2)\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "mpl.rcParams['figure.figsize'] = (10.0, 8.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's a matrix of which we're trying to compute the norm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n = 2\n",
        "A = np.random.randn(n, n)\n",
        "A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Recall:\n",
        "\n",
        "$$||A||=\\max_{\\|x\\|=1} \\|Ax\\|,$$\n",
        "\n",
        "where the vector norm must be specified, and the value of the matrix norm $\\|A\\|$ depends on the choice of vector norm.\n",
        "\n",
        "For instance, for the $p$-norms, we often write:\n",
        "\n",
        "$$||A||_2=\\max_{\\|x\\|=1} \\|Ax\\|_2,$$\n",
        "\n",
        "and similarly for different values of $p$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------\n",
        "We can approximate this by just producing very many random vectors and evaluating the formula:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xs = np.random.randn(n, 1000)\n",
        "xs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to bring all those vectors to have norm 1. First, compute the norms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p = 1\n",
        "norm_xs = np.sum(np.abs(xs)**p, axis=0)**(1/p)\n",
        "norm_xs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, divide by the norms and assign to `normalized_xs`:\n",
        "\n",
        "Then check the norm of a randomly chosen vector.\n",
        "\n",
        " $${\\rm normalized\\_xs}= \\frac{x}{||x||_p}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalized_xs = xs/norm_xs\n",
        "la.norm(normalized_xs[:, 99], p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at all `normalized_xs` vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(normalized_xs[0], normalized_xs[1], \"b.\")\n",
        "plt.gca().set_aspect(\"equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now apply $A$ to these normalized vectors:\n",
        "\n",
        " $${\\rm A\\_nxs}= A\\frac{x}{||x||_p}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "A_nxs = A.dot(normalized_xs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------\n",
        "Let's take a look again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(normalized_xs[0], normalized_xs[1], \"b.\", label=\"x\")\n",
        "plt.plot(A_nxs[0], A_nxs[1], \"r.\", label=\"Ax\")\n",
        "plt.legend()\n",
        "plt.gca().set_aspect(\"equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, compute norms of the $Ax$ vectors:\n",
        "\n",
        " $${\\rm norm\\_Axs}= ||Ax||_p$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "norm_Axs = np.sum(np.abs(A_nxs)**p, axis=0)**(1/p)\n",
        "norm_Axs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What's the biggest one?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.max(norm_Axs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare that with what `numpy` thinks the matrix norm is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "la.norm(A, p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}